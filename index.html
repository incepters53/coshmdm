<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CoShMDM</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Roboto" rel="stylesheet">
    <link rel="icon" href="./images/favicon.svg">
    <link rel="stylesheet" href="styles.css">

    <link rel="stylesheet" href="./animation-slider/css/index.css">
    <script src="./animation-slider/scripts/index.js"></script>

</head>
<body>
    <div class="container">
        <header>
            <h1 class="project-title">CoShMDM: Contact and Shape Aware Latent Motion Diffusion Model for Human Interaction Generation</h1>
        </header>



        <section class="authors">
            <div class="author">
                <a href=""><h3>***<sup>1,2</sup><span>,</span></h3></a>
                <a href=""><h3>***<sup>1</sup><span>,</span></h3></a>
                <a href=""><h3>***<sup>1,3</sup><span>,</span></h3></a>
                <a href=""><h3>***<sup>1</sup></h3></a>
            </div>
            
            <div class="affiliations">
                <p><sup>1</sup>*** <sup>2</sup>***</p>
                <p><sup>3</sup>***</p>
            </div>

        </section>





        <!-- Add new section for buttons -->
        <section class="project-links">
            <a href="#" class="link-button paper disabled">
                <svg class="icon" viewBox="0 0 24 24" width="24" height="24">
                    <path d="M14,2H6A2,2 0 0,0 4,4V20A2,2 0 0,0 6,22H18A2,2 0 0,0 20,20V8L14,2M18,20H6V4H13V9H18V20Z"/>
                </svg>
                Paper
            </a>
            <a href="#" class="link-button arxiv disabled">
                <svg class="icon" viewBox="0 0 24 24" width="24" height="24">
                    <path d="M19 3H5C3.9 3 3 3.9 3 5V19C3 20.1 3.9 21 5 21H19C20.1 21 21 20.1 21 19V5C21 3.9 20.1 3 19 3M9.5 11.5C9.5 12.3 8.8 13 8 13H7V15H5.5V9H8C8.8 9 9.5 9.7 9.5 10.5V11.5M14.5 13.5C14.5 14.3 13.8 15 13 15H10.5V9H13C13.8 9 14.5 9.7 14.5 10.5V13.5M18.5 10.5H17V11.5H18.5V13H17V15H15.5V9H18.5V10.5M7 10.5H8V11.5H7V10.5M12 13.5H13V10.5H12V13.5Z"/>
                </svg>
                arXiv
            </a>
            <a href="#" class="link-button video-link">
                <svg class="icon" viewBox="0 0 24 24" width="24" height="24">
                    <path d="M10,16.5V7.5L16,12M20,4.4C19.4,4.2 15.7,4 12,4C8.3,4 4.6,4.19 4,4.38C2.44,4.9 2,8.4 2,12C2,15.59 2.44,19.1 4,19.61C4.6,19.81 8.3,20 12,20C15.7,20 19.4,19.81 20,19.61C21.56,19.1 22,15.59 22,12C22,8.4 21.56,4.91 20,4.4Z"/>
                </svg>
                Video
            </a>
            <a href="https://github.com/Incepters53/coshmdm-code" class="link-button code">
                <svg class="icon" viewBox="0 0 24 24" width="24" height="24">
                    <path d="M12,2A10,10 0 0,0 2,12C2,16.42 4.87,20.17 8.84,21.5C9.34,21.58 9.5,21.27 9.5,21C9.5,20.77 9.5,20.14 9.5,19.31C6.73,19.91 6.14,17.97 6.14,17.97C5.68,16.81 5.03,16.5 5.03,16.5C4.12,15.88 5.1,15.9 5.1,15.9C6.1,15.97 6.63,16.93 6.63,16.93C7.5,18.45 8.97,18 9.54,17.76C9.63,17.11 9.89,16.67 10.17,16.42C7.95,16.17 5.62,15.31 5.62,11.5C5.62,10.39 6,9.5 6.65,8.79C6.55,8.54 6.2,7.5 6.75,6.15C6.75,6.15 7.59,5.88 9.5,7.17C10.29,6.95 11.15,6.84 12,6.84C12.85,6.84 13.71,6.95 14.5,7.17C16.41,5.88 17.25,6.15 17.25,6.15C17.8,7.5 17.45,8.54 17.35,8.79C18,9.5 18.38,10.39 18.38,11.5C18.38,15.32 16.04,16.16 13.81,16.41C14.17,16.72 14.5,17.33 14.5,18.26C14.5,19.6 14.5,20.68 14.5,21C14.5,21.27 14.66,21.59 15.17,21.5C19.14,20.16 22,16.42 22,12A10,10 0 0,0 12,2Z"/>
                </svg>
                Code
            </a>
        </section>

    </div>


    <section class="section-compare-video">
        <div class="compare-video" >
            <div class="video-container border">
                <video class="video-after" autoplay loop muted playsinline>
                    <source src="./videos-paper/split-slider-0.mp4" type="video/mp4">
                </video>
            <div class="video-before">
                <video autoplay loop muted playsinline>
                    <source src="./videos-paper/split-slider-2.mp4" type="video/mp4">
                </video>
            </div>
            <div class="slider">
                <div class="slider-handle"><span></span></div>
            </div>
        </div>

        <h2>Two people stand side by side, one person grabs the other person's <span class="blue-bold">left hand</span> with his/her <span class="blue-bold">right hand</span>, and they spin in a <span class="blue-bold">circle</span>.</h2>


    </section>




    <div class="full-width-container ">
        <div class="container">

            <section class="abstract">
                <h2>Abstract</h2>
                <p>
                    Generating realistic two-person interaction motions from text holds immense potential in computer vision and animations. While existing latent motion diffusion models offer compact and efficient representations, they are typically limited to a single canonical body shape and often fail to produce physically plausible contacts. As a result, the generated motion sequences exhibit substantial mesh penetrations and lack  interaction realism. To address these limitations, we propose a contact and shape-aware latent motion representation and diffusion model (CoShMDM) for generating realistic two-person interactions from text. Our framework begins by constructing contact-compatible motion using SMPL-based meshes and a normal alignment-based mesh contact matrix to capture fine-grained mesh-level contacts. To account for shape diversity, we incorporate SMPL shape parameters and iteratively learn contact dynamics across different body shapes. Additionally, a reinforcement learning-based mesh penetration avoidance policy network, guided by signed distance fields, is introduced to minimize mesh penetrations while preserving contact fidelity and shape-aware motion. We further employ a dual-encoder VQ-VAE to learn disentangled latent representations for motion and contact, which are then utilized in a text- and body-shape-conditioned diffusion model. To ensure spatial, temporal, and semantic coherence, we integrate a novel contact and motion consistency module into the diffusion transformer. Extensive evaluations on the InterHuman and InterX datasets demonstrate that our method outperforms state-of-the-art approaches, achieving 19% and 17.3% lower mesh penetration and 17.8% and 33.2% higher contact similarity, respectively.
                </p>
            </section>

        </div>
    </div>


    

        
    <div class="container evaluation">




        <section class="method">
            <h2>Proposed Method</h2>
            <h4 class="red">(Hover the mouse over image to Zoom)</h4> <br/>
    
            <figure class="zoom" onmousemove="zoom(event)" style="background-image: url(./images-paper/fig-model.png)">
                <img src="./images-paper/fig-model.png"/>
            </figure>
            <p>
                Overview of CoShMDM: (a) Contact and shape-aware latent motion representation, (b) Contact and shape-aware interaction motion diffusion model (CoShMDM).
            </p> 

        </section>

        <br/><br/>
        

        <section class="kf">
            <h2>Contact and Motion Consistency (CMC) Module</h2>
            <img src="./images-paper/fig-cmc.png" width="100%"/>
    
            <p>
                Visualization of Contact and Motion Consistency (CMC) Module. (Left) Mesh contact matrix encodes contact regions between interacting bodies. (Middle) A bipartite graph captures inter- and intra-skeletal relations. (Right) Features injected into the self-attention mechanism to enhance spatial and temporal coherence.
            </p>  

        </section>

        <br/><br/><br/><br/>


        <!-- <section class="image-caption">
            <p>FQK-T2M generates semantically accurate and contextually aligned human motions.</p>
        </section> -->


        <!-- Add this after your existing sections -->
        <section class="video-grid">
            <h3>Qualitative Results on InterX Dataset (Rendering Engine = Open 3D Engine-O3DE)</h3>

            <div class="grid-container">
                <!-- Grid Item 1 -->
                <div class="grid-item">
                    <div class="video-box">
                        <video autoplay loop muted playsinline width="365" height="252">
                            <source src="./videos-paper/11.mp4" type="video/mp4">
                        </video>
                    </div>
                    <h6 class="video-caption">
                        <span class="blue-bold">Prompt: </span> The first person extends his/her right hand over his/her head and waves at the second person, who then extends his/her right hand next to his/her head and waves back at the first person.  
                    </h6>
                </div>

                <!-- Grid Item 2 -->
                <div class="grid-item">
                    <div class="video-box">
                        <video autoplay loop muted playsinline width="365" height="252">
                            <source src="./videos-paper/505.mp4" type="video/mp4">
                        </video>
                    </div>
                    <h6 class="video-caption">
                        <span class="blue-bold">Prompt: </span> Two people stand side by side, with one person holding the other person's left upper arm using his/her right hand, as they move forward together.  
                    </h6>
                </div>

                <!-- Grid Item 3 -->
                <div class="grid-item">
                    <div class="video-box">
                        <video autoplay loop muted playsinline width="365" height="252">
                            <source src="./videos-paper/42.mp4" type="video/mp4">
                        </video>
                    </div>
                    <h6 class="video-caption">
                        <span class="blue-bold">Prompt: </span> The first person gently pushes the second person on his/her right shoulder from behind with his/her right hand, causing the second person to be pushed down to the ground.
                    </h6>
                </div>





                <!-- Grid Item 4 -->
                <div class="grid-item">
                    <div class="video-box">
                        <video autoplay loop muted playsinline width="365" height="252">
                            <source src="./videos-paper/55.mp4" type="video/mp4">
                        </video>
                    </div>
                    <h6 class="video-caption">
                        <span class="blue-bold">Prompt: </span> The first person softly pats the upper right part of the second person's back from behind using his/her right hand.  
                    </h6>
                </div>

                <!-- Grid Item 5 -->
                <div class="grid-item">
                    <div class="video-box">
                        <video autoplay loop muted playsinline width="365" height="252">
                            <source src="./videos-paper/71.mp4" type="video/mp4">
                        </video>
                    </div>
                    <h6 class="video-caption">
                        <span class="blue-bold">Prompt: </span> Two people stand facing each other. The first person takes a few steps towards the second person and then knocks him/her over with his/her left shoulder.
                    </h6>
                </div>

                <!-- Grid Item 6 -->
                <div class="grid-item">
                    <div class="video-box">
                        <video autoplay loop muted playsinline width="365" height="252">
                            <source src="./videos-paper/133.mp4" type="video/mp4">
                        </video>
                    </div>
                    <h6 class="video-caption">
                        <span class="blue-bold">Prompt: </span> The first person sits down. The second person stands behind him and puts both hands on his shoulders, massaging them gently at first and then vigorously.
                    </h6>
                </div>






                <!-- Grid Item 7 -->
                <div class="grid-item">
                    <div class="video-box">
                        <video autoplay loop muted playsinline width="365" height="252">
                            <source src="./videos-paper/173.mp4" type="video/mp4">
                        </video>
                    </div>
                    <h6 class="video-caption">
                        <span class="blue-bold">Prompt: </span> One person sits on the ground while the other person approaches from the left, grabs the first person's left arm with both hands, and assists him/her in standing up.
                    </h6>
                </div>

                <!-- Grid Item 8 -->
                <div class="grid-item">
                    <div class="video-box">
                        <video autoplay loop muted playsinline width="365" height="252">
                            <source src="./videos-paper/499.mp4" type="video/mp4">
                        </video>
                    </div>
                    <h6 class="video-caption">
                        <span class="blue-bold">Prompt: </span> Two people stand facing each other, dancing by raising their right hands high and waving them from side to side in the air. The first person lowers his/her hand, and the second person follows suit.
                    </h6>
                </div>

                <!-- Grid Item 9 -->
                <div class="grid-item">
                    <div class="video-box">
                        <video autoplay loop muted playsinline width="365" height="252">
                            <source src="./videos-paper/1149.mp4" type="video/mp4">
                        </video>
                    </div>
                    <h6 class="video-caption">
                        <span class="blue-bold">Prompt: </span> Both stand side by side, with their hands on their waists, jumping and alternating kicking their feet forward.
                    </h6>
                </div>



                <!-- Grid Item 10 -->
                <div class="grid-item">
                    <div class="video-box">
                        <video autoplay loop muted playsinline width="365" height="252">
                            <source src="./videos-paper/1084.mp4" type="video/mp4">
                        </video>
                    </div>
                    <h6 class="video-caption">
                        <span class="blue-bold">Prompt: </span> One person stands, raises his/her right hand, and waves to the other person who sits opposite him/her. The person sitting raises both hands to wave back.
                    </h6>
                </div>

                <!-- Grid Item 11 -->
                <div class="grid-item">
                    <div class="video-box">
                        <video autoplay loop muted playsinline width="365" height="252">
                            <source src="./videos-paper/6496.mp4" type="video/mp4">
                        </video>
                    </div>
                    <h6 class="video-caption">
                        <span class="blue-bold">Prompt: </span> Two people stand. One person holds out his/her left hand, while the other person holds out his/her right hand. They take turns guessing and then switch hands.
                    </h6>
                </div>

                <!-- Grid Item 12 -->
                <div class="grid-item">
                    <div class="video-box">
                        <video autoplay loop muted playsinline width="365" height="252">
                            <source src="./videos-paper/8497.mp4" type="video/mp4">
                        </video>
                    </div>
                    <h6 class="video-caption">
                        <span class="blue-bold">Prompt: </span> One person stands while the other walks forward and covers his/her mouth with one hand, then the person raises his/her hand and pushes the other person's hand away.
                    </h6>
                </div>

                

                
            </div>
        </section>

        <br/><br/><br/><br/><br/><br/>







        <section class="video-grid">
            <h3>Qualitative Results on InterHuman Dataset (Rendering Engine = Blender-Cycles)</h3>

            <div class="grid-container">
                <!-- Grid Item 1 -->
                <div class="grid-item">
                    <div class="video-box">
                        <video autoplay loop muted playsinline width="365" height="252">
                            <source src="./videos-paper/betas-1.mp4" type="video/mp4">
                        </video>
                    </div>
                    <h6 class="video-caption">
                        <span class="blue-bold">Prompt: </span> In an intense boxing match, one is continuously punching while the other is defending and counterattacking.  
                    </h6>
                </div>

                <!-- Grid Item 2 -->
                <div class="grid-item">
                    <div class="video-box">
                        <video autoplay loop muted playsinline width="365" height="252">Contact and Motion Consistency (CMC) Module. (Left) Mesh contact matrix encodes contact regions between interacting bodies. (Middle) A bipartite graph captures inter- and intra-skeletal relations. (Right) Features injected into the self-attention mechanism to enhance spatial and temporal coherence.
                            <source src="./videos-paper/betas-6.mp4" type="video/mp4">
                        </video>
                    </div>
                    <h6 class="video-caption">
                        <span class="blue-bold">Prompt: </span> Two humans stands straight and raise one arm while repeatedly exchanging greetings with each other. 
                    </h6>
                </div>

                <!-- Grid Item 3 -->
                <div class="grid-item">
                    <div class="video-box">
                        <video autoplay loop muted playsinline width="365" height="252">
                            <source src="./videos-paper/betas-3.mp4" type="video/mp4">
                        </video>
                    </div>
                    <h6 class="video-caption">
                        <span class="blue-bold">Prompt: </span> One person physically interacts with the other person by hitting and pushing, causing the other person to step backwards.
                    </h6>
                </div>
               

                
            </div>
        </section>

        <br/><br/><br/><br/><br/><br/>





















        <h3>Results for various Shape Parameters &beta;<sub>a</sub> and &beta;<sub>b</sub></h3>
        <!-- Add this after your existing sections -->
        <section class="video-grid">
            <div class="grid-container">
            <!-- Grid Item 1 -->
                <div class="grid-item">
                    <div class="video-box">
                        <video autoplay loop muted playsinline width="365" height="252">
                            <source src="./videos-paper/1/1 short-fat short-thin.mp4" type="video/mp4">
                        </video>
                    </div>

                </div>

                <!-- Grid Item 2 -->
                <div class="grid-item">
                    <div class="video-box">
                        <video autoplay loop muted playsinline width="365" height="252">
                            <source src="./videos-paper/1/1 short-normal normal.mp4" type="video/mp4">
                        </video>
                    </div>

                </div>

                <!-- Grid Item 3 -->
                <div class="grid-item">
                    <div class="video-box">
                        <video autoplay loop muted playsinline width="365" height="252">
                            <source src="./videos-paper/1/1 tall-normal short-fat.mp4" type="video/mp4">
                        </video>
                    </div>

                </div>
                
            </div>
        </section>

        <br />

        <h6 class="video-caption">
            <span class="blue-bold">Prompt: </span> One person opens his/her arms, leans forward at the waist, hugs the other person, and lightly pats him/her twice with his/her right hand. Then, the other person embraces his/her waist.
        </h6>

        <br /><br /><br />





        <section class="video-grid">
            <div class="grid-container">

                <!-- Grid Item 4 -->
                <div class="grid-item">
                    <div class="video-box">
                        <video autoplay loop muted playsinline width="365" height="252">
                            <source src="./videos-paper/47/47 short-fat short-thin.mp4" type="video/mp4">
                        </video>
                    </div>
                </div>

                <!-- Grid Item 5 -->
                <div class="grid-item">
                    <div class="video-box">
                        <video autoplay loop muted playsinline width="365" height="252">
                            <source src="./videos-paper/47/47 short-normal normal.mp4" type="video/mp4">
                        </video>
                    </div>
                </div>

                <!-- Grid Item 6 -->
                <div class="grid-item">
                    <div class="video-box">
                        <video autoplay loop muted playsinline width="365" height="252">
                            <source src="./videos-paper/47/47 tall-normal short-fat.mp4" type="video/mp4">
                        </video>
                    </div>
                </div>             
  
            </div>
        </section>

        <br />

        <h6 class="video-caption">
            <span class="blue-bold">Prompt: </span> The first person pulls the second person's forearms forward with both hands while stepping back themselves, causing the second person to be pulled forward several steps while turning right.
        </h6>

        <br/><br/><br/><br/>



        
    </div>


        <div class="full-width-container ">
            <div class="container">
    
                <!-- Add this after your existing sections -->
                <section class="two-column-grid">
                    <div class="two-column-grid-container">

                        <div class="grid-item">
                            <div class="column-box">
                                <h2>Normal Alignment-Based Mesh Contacts</h2>
                                <p> Mesh contact computed as normal alignment and centroid distance between face pairs, forming a contact matrix C<sup>i</sup>. </p>
                                <br /><br /><br />
                                <img src="./images-paper/fig-contacts.png" width="90%"/>
                            </div>
                        </div>

                        <div class="grid-item">

                            <div class="column-box">
                                <h2>Orientation Vectors and Interaction Features</h2>
                                <p> Interaction features include orientation vectors (head, chest, mid-hip), proximity, and trajectories of the interacting meshes M<sub>a</sub> and M<sub>b</sub>.</p>
                                <img src="./images-paper/fig-orientation-vectors.png" width="85%"/>
                            </div>
                        </div>

                    </div>

                </section>
            
            </div>
        </div>

   

    <div class="container">
    

    







    <!-- Evaluation and comparison with SOTA. -->
        <section class="evaluation">
            <br/><br/>
            <h2>Evaluation and Comparison with SOTA</h2>
            <br/>



            <!-- SOTA Comparison Prompt-1 -->
            <h3>Qualitative Evaluations against SOTA</h3>
            <h4>Qualitative comparison of our approach with InterMask, FreeMotion, and InterGen on the InterHuman inference.. For each text prompt, the corresponding generated motion is shown. Motion sequences are downsampled for clarity, character a is in blue mesh and character b in orange mesh. The red dotted regions highlighting anomalies, and green dotted regions denoting correct text-to-motion correspondences. While the mesh contact is threshold at 0.68.</h4>
            <img src="./images-paper/fig-sota-1.png" width="80%"/> 
            <br/>  <br/>  <br/>  
            <img src="./images-paper/fig-sota-2.png" width="80%"/>  
            <br/>  <br/>  <br/>  
            <img src="./images-paper/fig-additional-qualitative.png" width="80%"/>      
            <!--/ SOTA Comparison Prompt-1 -->
    
            
    
            

    
        
            <br/><br/><br/><br/>
            <!-- Qunat. HumanML3D. -->
            <h3>Quantitative Evaluation on InterHuman Dataset</h3>
            <h4>Quantitative evaluation on the InterHuman test sets. &plusmn; indicates a 95% confidence interval. (&#8593;) denotes greater the better, (&#8595;) represents smaller the better and, (&#8594;) means the closer to ground truth the better. <b>Bold</b> face indicates the best result, while <u>underlined</u> refers to the second best.</h4>
            <img src="./images-paper/fig-quant-eval-interhuman.png" width="70%"/>          
            <!--/ Qunat. HumanML3D. -->
    
            <br/><br/><br/><br/>
            <!-- Qunat. KITML. -->
            <h3>Quantitative Evaluation on InterX Dataset</h3>
            <h4>Quantitative evaluation on the InterX dataset. <b>Bold</b> face indicates the best result, while <u>underlined</u> refers to the second best.</h4>
            <img src="./images-paper/fig-quant-eval-interx.png" width="70%"/>
            <!--/ Qunat. KITML. -->
    
    
    
    
            <br/><br/><br/><br/>
            <!--  Ablation Studies. -->
            <h3>Ablation Studies</h3>
            <h4>Ablation on various model components of CoShMDM, token masking, and codebook choice on InterHuman test set.</h4>
            <img src="./images-paper/fig-ablation-1.png" width="50%"/>
          <!--/ Ablation Studies. -->
  
    </section>
    <!--/ Evaluation and comparison with SOTA. -->
  
  

    
</div>







<div class="full-width-container ">
    <div class="container">
        <section class="footer">
            <p>This project is supported by *** and ***.</p>
        </section>
    </div>
</div>




<script src="script.js"></script>

<script>
    // Initialize both viewers
    const viewer1 = new ImageSequenceViewer(
    document.getElementById('sequence-viewer-1'), 
    {
        folderPath: './interpolation/back_kick/',
        numFrames: 72,
        startFrame: 1,
        endFrame: 72,
        speed: 1.0,
        autoplay: true
    }
    );

    const viewer2 = new ImageSequenceViewer(
    document.getElementById('sequence-viewer-2'), 
    {
        folderPath: './interpolation/boxing/',
        numFrames: 512,
        startFrame: 1,
        endFrame: 512,
        speed: 1.0,
        autoplay: true
    }
    );
</script>


</body>
</html>
